import os
from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.embeddings import Embeddings
from transformers import AutoTokenizer, AutoModel
from langchain.docstore.document import Document
from typing import List


def build_chroma_index(docs: List[Document], index_path="chroma_index") -> Chroma:
    """
    –°—Ç—Ä–æ–∏—Ç Chroma –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ—ë –Ω–∞ –¥–∏—Å–∫
    """
    if not docs:
        raise ValueError("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.")

    # üí° –î–æ–±–∞–≤–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤
    for i, doc in enumerate(docs):
        doc.metadata["chunk_id"] = f"CHUNK-{i+1}"

    embeddings = HuggingFaceEmbeddings(model_name="intfloat/e5-large-v2")
    vectorstore = Chroma.from_documents(
        docs,
        embedding=embeddings,
        persist_directory=index_path,
    )

    print("Chroma –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
    return vectorstore




def load_chroma_index(index_path: str = "chroma_index") -> Chroma:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç Chroma –∏–Ω–¥–µ–∫—Å —Å –¥–∏—Å–∫–∞
    """
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/e5-large-v2")
    return Chroma(persist_directory=index_path, embedding_function=embeddings)

def get_retriever(k: int = 10, fetch_k: int = 128):
    chroma = load_chroma_index()
    return chroma.as_retriever(
        search_type="mmr",
        search_kwargs={"k": k, 'fetch_k': fetch_k}
    )
# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    from load_docs import load_docx_documents
    from chunking import split_documents

    docs = load_docx_documents(r"D:\R-STYLE WORK\study_rag")
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏
    chunks = split_documents(docs)
    print(f"–ü–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∞–Ω–∫–æ–≤
    build_chroma_index(chunks)
    retriever = get_retriever()
    results = retriever.invoke("–î–∞–π —Ç–æ—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–∞–ª—å–Ω—ã–π –≥—Ä—É–Ω—Ç")
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ: {len(results)}")
    for i, doc in enumerate(results, 1):
        print(f"\n=== –§—Ä–∞–≥–º–µ–Ω—Ç {i} ===")
        print(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {doc.metadata.get('source', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        print(doc.page_content.strip())